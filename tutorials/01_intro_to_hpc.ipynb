{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to High Performance Computing\n",
    "\n",
    "* [What is High Performance Computing (HPC)?](#What-is-High-Performance-Computing?)\n",
    "* [Why is it important?](#Why-is-it-important?)\n",
    "* [Where is it used?](#Where-is-it-used?)\n",
    "* [What are the components of HPC?](#What-are-the-components-of-HPC?)\n",
    " - [Master Node](#Master-Node)\n",
    " - [Compute Node](#Compute-Node)\n",
    " - [Shared file storage and network](#Shared-file-storage-and-network)\n",
    " - [Scheduler](#Scheduler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is High Performance Computing?\n",
    "\n",
    "High Performance Computing most generally refers to the practice of aggregating computing power in a way that delivers much higher performance than one could get out of a typical desktop computer or workstation in order to solve large problems in science, engineering, or business.\n",
    "\n",
    "**RocketML enables easy transition from desktop to HPC through Data Science Workbench**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is it important?\n",
    "\n",
    "- Solve problems 100X faster -- days to minutes\n",
    "- Solve intractable problems\n",
    "- Significant competitive advantage - Your competition might be already using HPC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where is it used?\n",
    "- Computer aided engineering (CAE): Automotive design and testing, transportation, structural, mechanical design \n",
    "- Chemical engineering: Process and molecular design \n",
    "- Digital content creation (DCC) and distribution: Computer aided graphics in film and media \n",
    "- Economics/financial: Wall Street risk analysis, portfolio management, automated trading \n",
    "- Electronic design and automation (EDA): Electronic component design and verification \n",
    "- Geosciences and geo-engineering: Oil and gas exploration and reservoir modeling \n",
    "- Mechanical design and drafting: 2D and 3D design and verification, mechanical modeling \n",
    "- Defense and energy: Nuclear stewardship, basic and applied research \n",
    "- Government labs: Basic and applied research \n",
    "- University/academic: Basic and applied research \n",
    "- Weather forecasting: Near term and climate/earth modeling\n",
    "\n",
    "Ref: HPC for Dummies by Douglas Eadline, PhD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the components of HPC?\n",
    "\n",
    "![cluster](images/Beowulf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master Node\n",
    "\n",
    "The application programs never see the computational nodes (also called slave computers) but only interact with the \"Master\" which is a specific computer handling the scheduling and management of the compute nodes.[13] In a typical implementation the Master has two network interfaces, one that communicates with the private Beowulf network for the slaves, the other for the general purpose network of the organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Node\n",
    "\n",
    "![compute-node](images/node_diagram.png)\n",
    "\n",
    "The processor contains multiple compute cores (usually shortened to core); 4 in the diagram above. Each core contains a floating point unit (FPU) which is responsible for actually performning the computations on the data and various fast memory caches which are responsible for holding data that is currently being worked on. The compute power of a processor generally depends on three things:\n",
    "\n",
    "The speed of the processor (2-3 GHz are common speeds on modern processors)\n",
    "The power of the floating point unit (generally the more modern the processor, the more powerful the FPU is)\n",
    "The number of cores available (12-16 cores are typical on modern processors)\n",
    "Often, HPC nodes have multiple processors (usually 2 processors per node) so the number of cores available on a node is doubled (i.e. 24-26 cores per node, rather than 12-16 cores per node). This configuration can have implications for performance.\n",
    "\n",
    "Each node also has a certain amount of memory available (also referred to as RAM or DRAM) in addtion to the processor memory caches. Modern compute nodes typically have in the range 64-256 GB of memory per node.\n",
    "\n",
    "Finally, each node also has access to storage (also called disk or file system) for persistent storage of data. As we shall see later, this storage is often shared across all nodes and there are often multiple different types of storage connected to a node.\n",
    "\n",
    "[Reference](https://epcced.github.io/hpc-intro/010-hpc-concepts/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Storage and File Systems\n",
    "The kind of computing that people do on HPC systems often involves very large files, and/or many of them. Further, the files have to be accessible from all of the front-end and compute nodes on the system. So most HPC systems have specialized file systems that are designed to meet these needs. Frequently, these specialized file systems are intended to be used only for short- or medium-term storage, not permanent storage. As a consequence of this, most HPC systems often have several different file systems available â€“ for example home, and scratch file systems. It can be very important to select the right file system to get the results you want (performance or permanence are the typical trade-offs). [Reference](https://epcced.github.io/hpc-intro/010-hpc-concepts/)\n",
    "\n",
    "**On DSW a folder named `/shared/` is accessible from both master and compute nodes**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduler\n",
    "In order to share these large systems among many users, it is common to allocate subsets of the compute nodes to tasks (or jobs), based on requests from users. These jobs may take a long time to complete, so they come and go in time. To manage the sharing of the compute nodes among all of the jobs, HPC systems use a batch system or scheduler. The batch system usually has commands for submitting jobs, inquiring about their status, and modifying them.\n",
    "[Reference](https://epcced.github.io/hpc-intro/010-hpc-concepts/)\n",
    "\n",
    "**On DSW _slurm_ scheduler is installed and setup. Data Scientists don't need to spend time configuring the scheduler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
