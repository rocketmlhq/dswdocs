{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import mlflow.pytorch\n",
    "from  mlflow.tracking import MlflowClient\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "\n",
    "kwargs = {}\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=128, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"pytorch_exp_1\"\n",
    "tracking_uri = os.environ.get(\"TRACKING_URL\")\n",
    "client = MlflowClient(tracking_uri=tracking_uri)\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "experiments = client.list_experiments()\n",
    "\n",
    "experiment_names = []\n",
    "for exp in experiments:\n",
    "    experiment_names.append(exp.name)\n",
    "if experiment_name not in experiment_names:\n",
    "    try:\n",
    "        mlflow.create_experiment(experiment_name)\n",
    "    except:\n",
    "        pass\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch model initialized\n",
      "torch.float32\n",
      "Predicting 128 samples\n",
      "\n",
      "Sample predictions\n",
      "Sample 0 : Ground truth is \"3\", model prediction is \"3\"\n",
      "Sample 1 : Ground truth is \"1\", model prediction is \"1\"\n",
      "Sample 2 : Ground truth is \"3\", model prediction is \"3\"\n",
      "Sample 3 : Ground truth is \"2\", model prediction is \"2\"\n",
      "Sample 4 : Ground truth is \"1\", model prediction is \"8\"\n"
     ]
    }
   ],
   "source": [
    "run_id = \"e41989fbd5334b7591a8fe856c7bc907\"\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "    loaded_model = mlflow.pyfunc.load_model(mlflow.get_artifact_uri(\"pytorch-model\"))\n",
    "\n",
    "    # Extract a few examples from the test dataset to evaulate on\n",
    "    eval_data, eval_labels = next(iter(test_loader))\n",
    "    print(eval_data.dtype)\n",
    "    # Make a few predictions\n",
    "    predictions = loaded_model.predict(eval_data).data.max(1)[1]\n",
    "    template = 'Sample {} : Ground truth is \"{}\", model prediction is \"{}\"'\n",
    "    print(\"\\nSample predictions\")\n",
    "    for index in range(5):\n",
    "        print(template.format(index, eval_labels[index], predictions[index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/home/ubuntu/mnist_png/testing/0/10.png\"\n",
    "cvdata = cv2.imread(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "_path = \"/home/ubuntu/mnist_png/testing/\"\n",
    "file_list = [y for x in os.walk(_path) for y in glob(os.path.join(x[0], '*.png'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_labels = []\n",
    "for _file in file_list:\n",
    "    correct_labels.append(_file.split(\"/\")[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = min(len(file_list),100)\n",
    "file_list = file_list[:test_size]\n",
    "correct_labels = correct_labels[:test_size]\n",
    "nparray_list = []\n",
    "for _file in file_list:\n",
    "    with open(_file, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    base64_decoded = base64.b64decode(encoded_string)\n",
    "    image = Image.open(io.BytesIO(base64_decoded))\n",
    "    image_np = np.array(image,dtype=np.uint8)\n",
    "    image_np = np.expand_dims(image_np,axis=0)\n",
    "    nparray_list.append(image_np)\n",
    "nparray = np.stack(nparray_list,axis=0).astype(np.float32)\n",
    "torch_tensor = torch.from_numpy(nparray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"8ae8c49e85f24f98a6b33a4e52c9f7bb\"\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "    loaded_model = mlflow.pyfunc.load_model(mlflow.get_artifact_uri(\"pytorch-model\"))\n",
    "\n",
    "    # Make a few predictions\n",
    "    predictions = loaded_model.predict(torch_tensor).data.max(1)[1]\n",
    "    template = 'Sample {} : Ground truth is \"{}\", model prediction is \"{}\"'\n",
    "    print(\"\\nSample predictions\")\n",
    "    for index in range(100):\n",
    "        print(template.format(index,correct_labels[index],predictions[index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = min(len(file_list),100)\n",
    "file_list = file_list[:test_size]\n",
    "encoded_string_list = []\n",
    "# correct_labels = correct_labels[:test_size]\n",
    "nparray_list = []\n",
    "for _file in file_list:\n",
    "    with open(_file, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    encoded_string_list.append(encoded_string)\n",
    "input_df = pd.DataFrame(encoded_string_list,columns=[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch model initialized\n",
      "Predicting 100 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 4, 3, 3, 5, 5, 3, 5, 5, 5, 7, 5, 5, 5, 0, 5, 5, 5, 3, 9, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 5, 5,\n",
       "       8, 5, 5, 5, 5, 5, 5, 5, 6, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5,\n",
       "       5, 5, 0, 5, 5, 3, 5, 5, 2, 5, 5, 5, 5, 9, 5, 8, 5, 8, 3, 5, 5, 5,\n",
       "       5, 8, 1, 5, 3, 5, 5, 5, 3, 5, 6, 5])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = \"9fb2052dc0da45f5b888cfa645666ef2\"\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "    loaded_model = mlflow.pyfunc.load_model(mlflow.get_artifact_uri(\"pytorch-model\"))\n",
    "\n",
    "    # Make a few predictions\n",
    "    predictions = loaded_model.predict(input_df)\n",
    "#     template = 'Sample {} : Ground truth is \"{}\", model prediction is \"{}\"'\n",
    "#     print(\"\\nSample predictions\")\n",
    "#     for index in range(100):\n",
    "#         print(template.format(index,correct_labels[index],predictions[index]))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda_env[\"dependencies\"].append(\"cpuonly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'mlflow-env',\n",
       " 'channels': ['defaults', 'conda-forge', 'pytorch'],\n",
       " 'dependencies': ['python=3.7.7',\n",
       "  'pytorch=1.7.1',\n",
       "  'torchvision=0.8.2',\n",
       "  'pip',\n",
       "  {'pip': ['mlflow', 'cloudpickle==1.4.1']},\n",
       "  'cpuonly']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conda_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 3, 3, 5, 5, 3, 5, 5, 5, 7, 5, 5, 5, 0, 5, 5, 5, 3, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 6, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 0, 5, 5, 3, 5, 5, 2, 5, 5, 5, 5, 9, 5, 8, 5, 8, 3, 5, 5, 5, 5, 8, 1, 5, 3, 5, 5, 5, 3, 5, 6, 5]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = \"https://awfqvt3.azure.babyrocket.net/invocations\"\n",
    "#url = \"https://63gytpm.azure.babyrocket.net/invocations\"\n",
    "data_json = input_df.to_json(orient=\"split\",index=False)\n",
    "headers = {\"Content-Type\":\"application/json; format=pandas-split\"}\n",
    "response = requests.post(url,data=data_json,headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
